<!DOCTYPE html>
<html><head>
	<meta name="generator" content="Hugo 0.91.2" />
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Milton Osiel Candela Leal">
    <link rel="stylesheet" href="style.min.css">
<style>
  .container {
    display: flex;
    justify-content: space-between;
    align-items: center;
    margin-bottom: -10px;
  }
</style>
	
<title>Milton O. Candela-Leal</title>
</head>
<body><header id="banner">
    <h2><a href="https://miltoncandela.github.io/">Milton Candela</a></h2>
    <nav>
        <ul>
            <li>
                <a href="publications.html" title="Publications">Publications</a>
            </li>
            <li>
                <a href="milestones.html" title="Milestones">Milestones</a>
            </li>
            <li>
                <a href="projects.html" title="Projects">Projects</a>
            </li>
        </ul>
    </nav>
</header>
<main id="content">
<article>

<header id="post-header">
    <h1 style="text-align: center">Published Projects</h1>
        <div></div>
</header>

<h3 style="text-align: right">Cognitive Neuroscience</h3>

<div class="container"><div><p><b>Real-time Emotion Recognition</b></p></div><div><p style="text-align: right;">2022-2023</p></div></div>
<em>(Neurohumanities Lab)</em><br>
- Brain-Computer Interface based on the Database for Emotion Analysis using Physiological Signals (DEAP) in 8-channel EEG via PCA and RF <a href="https://doi.org/10.3389/fnhum.2024.1319574">[paper]</a>; <a href="https://github.com/miltoncandela/neurohumanities-lab">[repo]</a>

<figure><img src="neuroh1.png" width="500px"/></figure>
<figure><img src="neuroh2.png" width="500px"/>
    <figcaption>
        <p><sup>Blanco-Ríos, Candela-Leal et al. (2024) <em>Front. Hum. Neurosci.</em></sup></p>
    </figcaption>
</figure>

<div class="container"><div><p><b>Mental Fatigue Prediction</b></p></div><div><p style="text-align: right;">2021</p></div></div>
<em>(Advanced Learner Assistance System [ALAS])</em><br>
- 8-channel EEG <a href="https://doi.org/10.3390/ijerph182211891">[paper]</a>, real-time cloud-based implementation <a href="https://ieomsociety.org/proceedings/2021monterrey/487.pdf">[proceeding]</a>, &ensp; 4-channel EEG <a href="https://doi.org/10.1109/IEEECONF53024.2021.9733770">[proceeding]</a>, real-time implementation <a href="https://doi.org/10.13140/RG.2.2.30051.12329">[poster]</a>; <a href="https://github.com/miltoncandela/ALAS-project">[repo]</a>, <a href="https://github.com/miltoncandela/real-time-biofeedback">[repo]</a>

<figure><img src="alas1.png" width="500px"/></figure>
<figure><img src="alas2.png" width="500px"/>
    <figcaption>
        <p><sup>Aguilar-Herrera et al. (2021) <em>1st FEI-WS</em></sup></p>
    </figcaption>
</figure>

<div class="container"><div><p><b>Interest in STEM Prediction</b></p></div><div><p style="text-align: right;">2021</p></div></div>
<em>(Talent and Passion Detection Through Biometrics)</em><br>
- Subject-analysis <a href="https://ieomsociety.org/proceedings/2021monterrey/485.pdf">[proceeding]</a>, Machine Learning model <a href="https://doi.org/10.1109/IEEECONF53024.2021.9733772">[proceeding]</a>, in-depth Power Spectral Density and Functional Connectivity analysis <a href="https://www.sciencedirect.com/journal/thinking-skills-and-creativity">[paper]</a>; <a href="https://github.com/miltoncandela/STEM-talent-detection">[repo]</a>

<figure><img src="stem.png" width="500px"/>
    <figcaption>
        <p><sup>Candela-Leal et al. <em>(under review)</em></sup></p>
    </figcaption>
</figure>

<h3 style="text-align: right">Computational Neuroscience</h3>

<div class="container"><div><p><b>FeTA Challenge @ MICCAI </b></p></div><div><p style="text-align: right;">2024</p></div></div>
- Trained a 7-label fetal MRI U-Net model zoo with spatial, intensity and resolution augmentation for enhanced multi-site generalization; <a href="https://doi.org/10.13140/RG.2.2.34905.94561">[poster]</a>

<figure><img src="feta_pipeline.png" width="500px"/>
    <figcaption>
        <p><sup>Candela-Leal et al. (2024) <em>27th MICCAI</em></sup></p>
    </figcaption>
</figure>

<h3 style="text-align: right">Human Biomechanics</h3>

<div class="container"><div><p><b>Biomechanical Force Prediction</b></p></div><div><p style="text-align: right;">2021-2022</p></div></div>
<em>(Biomechanics for the Digital Twin)</em><br>
- RNN proof-of-concept model design using external dataset <a href="https://doi.org/10.3390/app12115424">[paper]</a>, RNN model fitting by gathering and using own data <a href="https://doi.org/10.1109/IEEECONF56852.2023.10104757">[proceeding]</a>; <a href="https://github.com/miltoncandela/rnn-force-prediction">[repo]</a>

<figure><img src="biomec.png" width="500px"/>
    <figcaption>
        <p><sup>Candela-Leal et al. (2022) <em>Appl. Sci.</em></sup></p>
    </figcaption>
</figure>

<header id="post-header">
    <h1 style="text-align: center">Non-Published Projects</h1>
        <div></div>
</header>

<h3 style="text-align: right">Cognitive Neuroscience</h3>

<div class="container"><div><p><b>Cognitive Load Dynamics in Chess</b></p></div><div><p style="text-align: right;">2023</p></div></div>
- Calculated Task Completion Time (TCT) based on EEG biomarker theta C4, validated with Cognitive Load Theory (CLT) stratifying by chess level; <a href="tec_slides.pdf">[slides]</a>

<figure><img src="chess1.png" width="500px"/></figure>
<figure><img src="chess2.png" width="500px"/></figure>

<div class="container"><div><p><b>Brain on Acting</b></p></div><div><p style="text-align: right;">2022</p></div></div>
- Unveil brain-to-brain communication patterns between actors during an acted scene via brain connectivity analysis and bisprectrum calculation; <a href="boa_poster.pdf">[poster]</a>

<figure><img src="boa1.png" width="500px"/></figure>
<figure><img src="boa2.png" width="500px"/></figure>

<h3 style="text-align: right">Computational Neuroscience</h3>

<div class="container"><div><p><b>High-res Fetal Subplate Segmentation</b></p></div><div><p style="text-align: right;">2024</p></div></div>
- Implemented Bivariate Gaussian Smoothing (BGS) for fast construction of a high-resolution training dataset, further fitted into a pre-trained U-Net; <a href="highres_slides.pdf">[slides]</a>

<figure><img src="subplate1.png" width="500px"/></figure>
<figure><img src="subplate3.png" width="500px"/></figure>
	
<div class="container"><div><p><b>Non-linear qMRI for CHD Classification</b></p></div><div><p style="text-align: right;">2024</p></div></div>
- Designed Recursive RF importance (RRFi) for feature selection (20,453), leading to a parsimonious 5-feature kNN model (F1-score = 0.88); <a href="chd_slides.pdf">[slides]</a>

<figure><img src="chd1.png" height="500px"/></figure>

 <!-- <div class="container"><div><p><b>Unsupervised VAE-GAN for Anomaly</b></p></div><div><p style="text-align: right;">2024</p></div></div> -->
 <!-- - Trained an age-informed model in typically developed fetal brains with a novel age encoding: Bidirectional Ordinary Encoding (BOE) (AUC = 90%); <a href="gan_slides.pdf">[slides]</a> -->

 <!-- <figure><img src="gan1.png" width="500px"/></figure> -->
 <!-- <figure><img src="gan2.png" width="500px"/></figure> -->

 <h3 style="text-align: right">Human-Machine Interaction</h3>

<div class="container"><div><p><b>Digital Twin of the Workspace</b></p></div><div><p style="text-align: right;">2022</p></div></div>
- Design of a throughput monitoring system via a Human Action Recognition (HAR) CNN + RNN DL model, using a 3D camera and a 360° LiDAR pointcloud sensor, in addition to CV tracking using CCTV footage; <a href="cl_poster.pdf">[poster]</a> <a href="cl_report.pdf">[technical report]</a>

<figure><img src="dt1.png" width="500px"/></figure>
<figure><img src="dt2.png" width="500px"/></figure>

<header id="post-header">
    <h1 style="text-align: center">University/Personal Projects</h1>
        <div></div>
</header>

<div class="container"><div><p><b>Closed-loop BCI for Attention</b></p></div><div><p style="text-align: right;">2024</p></div></div>
- Trained a 3-feature MLR model with 0.72 R<sup>2</sup> that predicted attention by collecting 4-channel EEG CPT-II data, implemented in a real-time analog haptic neurofeedback and validated using a 12-min video; <a href="cl_poster.pdf">[poster]</a> <a href="cl_report.pdf">[technical report]</a>

<figure><img src="cl1.png" width="500px"/></figure>
<figure><img src="cl2.png" width="500px"/></figure>

<div class="container"><div><p><b>Knee Flexion Angle Estmation</b></p></div><div><p style="text-align: right;">2022-2023</p></div></div>
- Leveraged by a L515 depth camera and 2D OpenPose keypoints, a real-time algorithm estimated knee flexion angle during a drop vertical jump, to identify risk factors for anterior cruciate ligament injury; <a href="biomec_rodilla_poster.pdf">[poster]</a> <a href="biomec_rodilla_report.pdf">[technical report]</a>
	
<figure><img src="biomec_rodilla1.png" width="500px"/></figure>
<figure><img src="biomec_rodilla2.JPG" width="500px"/></figure>

<div class="container"><div><p><b>Predictive Text Application</b></p></div><div><p style="text-align: right;">2020-2021</p></div></div>
- Capstone project for JHU's <a href="https://www.coursera.org/account/accomplishments/specialization/certificate/5EGJ8E577UKX">Data Science specialization</a> (288 h), fitted a Katz backoff model to predict next word via n-grams; <a href="https://github.com/miltoncandela/data-science-JHU">[repo]</a> <a href="milestone_report.html">[milestone report]</a>

<figure><img src="textpred.png" width="500px"/>
    <figcaption>
        <p><sup>Application <a href="https://milkbacon.shinyapps.io/Text-predicting/">demo</a> written on R and built using shiny; hosted at RPubs</sup></p>
    </figcaption>
</figure>

</article>

</ul>
        </main><footer id="footer">
    Last updated November 2024
</footer>
</body>
</html>
